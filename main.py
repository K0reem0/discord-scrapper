import discord
from discord.ext import commands
from PIL import Image
from io import BytesIO
import dropbox
import re
import os
import asyncio
import uuid
import zipfile
import shutil
# Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Selenium
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service 
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException, NoSuchElementException
import requests
import time 

# --- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„Ø«ÙˆØ§Ø¨Øª ---
DISCORD_BOT_TOKEN = os.getenv("DISCORD_BOT_TOKEN")
DROPBOX_ACCESS_TOKEN = os.getenv("DROPBOX_ACCESS_TOKEN")

MIN_WIDTH = 800
CLEANUP_DELAY_SECONDS = 1800
LOCAL_TEMP_DIR = "manga_temp" 
IMAGE_DOWNLOAD_TIMEOUT = 30 
VALID_FORMATS = ['jpg', 'jpeg', 'webp', 'png']

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙˆØª
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix='!', intents=intents)
dbx = dropbox.Dropbox(DROPBOX_ACCESS_TOKEN)

# --- Ø¯Ø§Ù„Ø© ØªÙ‡ÙŠØ¦Ø© Ù…ØªØµÙØ­ Selenium (Ù…ÙØ«Ø¨ØªØ© Ù„Ù€ Heroku) ---
def init_driver():
    """
    ØªÙ‡ÙŠØ¦Ø© Ù…ØªØµÙØ­ Chrome ÙÙŠ ÙˆØ¶Ø¹ Headless.
    """
    chrome_bin = os.environ.get("CHROME_BIN") or os.environ.get("GOOGLE_CHROME_BIN")
    chromedriver_path = os.environ.get("CHROMEDRIVER_PATH")
    
    if not chrome_bin or not chromedriver_path:
        print("[CRITICAL ERROR] Heroku environment variables (CHROME_BIN/CHROMEDRIVER_PATH) not found.")
        return None

    chrome_options = Options()
    
    # Ø®ÙŠØ§Ø±Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù€ Headless
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--disable-dev-shm-usage")
    # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ù‡Ù„Ø© Ù„Ø§Ù†ØªØ¸Ø§Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©
    chrome_options.page_load_strategy = 'normal' 
    
    chrome_options.binary_location = chrome_bin 

    try:
        service = Service(executable_path=chromedriver_path)
        # Ø²ÙŠØ§Ø¯Ø© Ù…Ù‡Ù„Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…ØªØµÙØ­ Ø¥Ù„Ù‰ 60 Ø«Ø§Ù†ÙŠØ©
        driver = webdriver.Chrome(service=service, options=chrome_options)
        driver.set_page_load_timeout(60) # Ù…Ù‡Ù„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©
        print("[INFO] Chrome Driver initialized successfully using Heroku static paths and Service object.")
        return driver
    except WebDriverException as e:
        print(f"[CRITICAL ERROR] Failed to initialize Chrome Driver: {e}")
        return None


# --- Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© (ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø¯Ø§Ù„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ± Ù‡Ù†Ø§) ---

def download_and_check_image(image_url, target_format="jpg"):
    """
    ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©ØŒ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù…Ù‡Ø§ØŒ ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ù„Ù€ format Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù.
    (ØªÙ… Ø¥Ø¶Ø§ÙØ© User-Agent ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø©)
    """
    target_format = target_format.lower()
    
    if target_format in ['jpg', 'jpeg']:
        save_format = 'jpeg'
        ext = 'jpg'
    elif target_format == 'webp':
        save_format = 'webp'
        ext = 'webp'
    elif target_format == 'png':
        save_format = 'png'
        ext = 'png'
    else:
        save_format = 'jpeg'
        ext = 'jpg'
        
    # Ø¥Ø¶Ø§ÙØ© User-Agent Ù„Ø²ÙŠØ§Ø¯Ø© Ù…ÙˆØ«ÙˆÙ‚ÙŠØ© Ø§Ù„ØªØ­Ù…ÙŠÙ„
    headers = {
        "User-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36"
    }

    try:
        response = requests.get(image_url, stream=True, timeout=IMAGE_DOWNLOAD_TIMEOUT, headers=headers)
        response.raise_for_status() 
        
        image_bytes = BytesIO(response.content)
        img = Image.open(image_bytes)
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ù„Ù€ RGB Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† PNG
        if save_format != 'png' and img.mode != 'RGB':
            img = img.convert("RGB")
        
        if img.width >= MIN_WIDTH:
            return img, ext, save_format
        else:
            print(f"[ERROR LOG] Skipping image {image_url}: Width {img.width}px is less than {MIN_WIDTH}px.")
            return None, None, None
            
    except Exception as e:
        if isinstance(e, requests.exceptions.HTTPError):
            print(f"[ERROR LOG] HTTP Error processing image {image_url}: {e.response.status_code}")
        else:
            print(f"[ERROR LOG] General Error processing image {image_url}: {e}")
            
        return None, None, None


# Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ (Async)
async def cleanup_dropbox_file(dropbox_path: str, delay_seconds: int):
    """ÙŠÙ†ØªØ¸Ø± 15 Ø¯Ù‚ÙŠÙ‚Ø© Ø«Ù… ÙŠØ­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¶ØºÙˆØ· Ù…Ù† Dropbox."""
    await asyncio.sleep(delay_seconds)
    try:
        dbx.files_delete_v2(dropbox_path)
        print(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ù…Ù„Ù ZIP ({dropbox_path}) Ø¨Ù†Ø¬Ø§Ø­ Ø¨Ø¹Ø¯ {delay_seconds} Ø«ÙˆØ§Ù†ÙŠ.")
    except Exception as e:
        print(f"âŒ ÙØ´Ù„ Ø­Ø°Ù Ù…Ù„Ù ZIP ({dropbox_path}): {e}")


def merge_chapter_images(chapter_folder: str, image_format: str):
    """
    ØªÙ†ÙØ° Ø¯Ù…Ø¬ Ø§Ù„ØµÙˆØ± Ù„Ù…Ù„ÙØ§Øª JPG/JPEG ÙÙ‚Ø·.
    """
    if image_format.lower() not in ['jpg', 'jpeg']:
        print(f"[INFO] Skipping merge: Merge is only supported for JPG/JPEG format.")
        return

    jpeg_files = sorted([f for f in os.listdir(chapter_folder) if f.lower().endswith(('.jpg', '.jpeg'))])
    
    num_jpeg = len(jpeg_files)
    merge_list = [] 
    
    i = 0
    while i + 1 < num_jpeg:
        file1_path = os.path.join(chapter_folder, jpeg_files[i])
        file2_path = os.path.join(chapter_folder, jpeg_files[i+1])
        merge_list.append((file1_path, file2_path))
        i += 2
        
    for file1_path, file2_path in merge_list:
        try:
            img1 = Image.open(file1_path).convert("RGB") 
            img2 = Image.open(file2_path).convert("RGB")
            
            max_width = max(img1.width, img2.width)
            total_height = img1.height + img2.height
            
            merged_img = Image.new('RGB', (max_width, total_height))
            merged_img.paste(img1, (0, 0)) 
            merged_img.paste(img2, (0, img1.height)) 
            
            merged_img.save(file1_path, 'jpeg', quality=90) 
            os.remove(file2_path)
            print(f"Merged {os.path.basename(file1_path)} and {os.path.basename(file2_path)}")

        except Exception as e:
            print(f"[ERROR LOG] Failed to merge images: {e}")
            continue

    # Ø¥Ø¹Ø§Ø¯Ø© ØªØ±Ù‚ÙŠÙ… Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    final_files = sorted([f for f in os.listdir(chapter_folder) if f.lower().endswith(tuple(VALID_FORMATS))])
    
    for index, filename in enumerate(final_files):
        ext = filename.split('.')[-1]
        new_filename = f"{index + 1:03d}.{ext}"
        
        if filename != new_filename:
            try:
                os.rename(os.path.join(chapter_folder, filename), os.path.join(chapter_folder, new_filename))
            except Exception as e:
                print(f"[ERROR LOG] Failed to rename file: {e}")


# --- Ù…Ù‡Ù…Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø© (Ù…ØªØ²Ø§Ù…Ù†Ø© - ØªÙ… ØªØ¹Ø¯ÙŠÙ„Ù‡Ø§ Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Lazy Loading) ---
def _process_manga_download(url, chapter_number, chapters, merge_images, image_format):
    """
    ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„ Ù…Ù†Ø·Ù‚ Ø§Ù„Ù€ Selenium ÙˆØ§Ù„Ù…Ù„ÙØ§Øª. ØªÙØ´ØºÙ„ ÙÙŠ Ø®ÙŠØ· Ù…Ù†ÙØµÙ„.
    ØªØ¹ÙŠØ¯ Ù‚Ø§Ù…ÙˆØ³Ù‹Ø§ Ø¨Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©.
    """
    driver = None
    chapters_processed = 0
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø¤Ù‚Øª Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡
    if os.path.exists(LOCAL_TEMP_DIR): shutil.rmtree(LOCAL_TEMP_DIR)
    os.makedirs(LOCAL_TEMP_DIR, exist_ok=True)
    
    try:
        # 1. ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ØªØµÙØ­
        driver = init_driver()
        if not driver:
            return {"success": False, "error": "ÙØ´Ù„ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ù…ØªØµÙØ­ Chrome/Selenium."}

        # 2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø§Ø¨Ø· ÙˆØªØ­Ø¯ÙŠØ¯ Ù†Ø·Ø§Ù‚ Ø§Ù„ÙØµÙˆÙ„
        base_url_pattern = url
        url_contains_chapter_num = False
        
        match = re.search(r'(chapter|no|epi)[\-_=]\d+', url, re.IGNORECASE)
        
        if match:
            base_url_pattern = re.sub(r'(chapter|no|epi)[\-_=]\d+', r'\1-{}', url, re.IGNORECASE)
            url_contains_chapter_num = True
        
        if not url_contains_chapter_num and chapters > 1:
            chapters = 1

        chapter_range = range(chapter_number, chapter_number + chapters) 
        
        # 3. Ø­Ù„Ù‚Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙØµÙˆÙ„
        for current_chapter_num in chapter_range:
            if url_contains_chapter_num:
                current_url = base_url_pattern.format(current_chapter_num)
            else:
                current_url = url
                
            local_chapter_folder = os.path.join(LOCAL_TEMP_DIR, str(current_chapter_num))
            images_downloaded = 0
            
            try:
                os.makedirs(local_chapter_folder, exist_ok=True)
                
                driver.get(current_url)
                
                # 3.1 Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø­ØªÙ‰ ØªØ­Ù…ÙŠÙ„ Ø£ÙˆÙ„ ØµÙˆØ±Ø© (ÙŠØ´Ù…Ù„ Ø§Ù†ØªØ¸Ø§Ø± data-src)
                WebDriverWait(driver, 45).until( 
                    EC.presence_of_element_located((By.CSS_SELECTOR, 'img.page-image, img[src*="cdn"], img[src*="data"], img[data-src]'))
                )
                
                # 3.2 Ø§Ù„ØªÙ…Ø±ÙŠØ± Ù„Ø£Ø³ÙÙ„ Ø§Ù„ØµÙØ­Ø© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Lazy Loading
                last_height = driver.execute_script("return document.body.scrollHeight")
                scroll_attempts = 0
                max_scrolls = 10 
                
                while scroll_attempts < max_scrolls:
                    # Ø§Ù„ØªÙ…Ø±ÙŠØ± Ù„Ø£Ø³ÙÙ„
                    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                    time.sleep(3) # Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
                    
                    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ…Ø±ÙŠØ±
                    new_height = driver.execute_script("return document.body.scrollHeight")
                    
                    if new_height == last_height:
                        # Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ØŒ Ù†ØªÙˆÙ‚Ù
                        break
                        
                    last_height = new_height
                    scroll_attempts += 1
                
                # 3.3 Ø§Ø³ØªØ®Ù„Ø§Øµ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØµÙˆØ± (Ø§Ù„Ø¨Ø­Ø« ÙÙŠ src Ùˆ data-src)
                image_elements = driver.find_elements(By.TAG_NAME, 'img')
                
                image_srcs = []
                for img in image_elements:
                    src = img.get_attribute('src')
                    data_src = img.get_attribute('data-src') # Ù„Ø§Ù‚ØªÙ†Ø§Øµ Lazy Load
                    
                    # Ù†Ø³ØªØ®Ø¯Ù… data-src Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ ÙˆØºÙŠØ± ÙØ§Ø±Øº
                    if data_src and not data_src.startswith('data:'):
                        image_srcs.append(data_src)
                    # ÙˆØ¥Ù„Ø§ØŒ Ù†Ø³ØªØ®Ø¯Ù… src Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ ÙˆØºÙŠØ± ÙØ§Ø±Øº
                    elif src and not src.startswith('data:'):
                        image_srcs.append(src)
                        
                # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙØ§Ø¡Ø©
                image_srcs = list(dict.fromkeys(image_srcs))


                if not image_srcs: 
                    print(f"[ERROR LOG] No unique image URLs found in chapter {current_chapter_num}")
                    if os.path.exists(local_chapter_folder): shutil.rmtree(local_chapter_folder)
                    continue
                
                # ØªÙ†Ø²ÙŠÙ„ ÙˆØ­ÙØ¸ Ø§Ù„ØµÙˆØ±
                image_counter = 1
                for img_src in image_srcs:
                    if not img_src or img_src.startswith('data:'): continue

                    img_obj, ext, save_format = download_and_check_image(img_src, image_format)
                    
                    if img_obj:
                        filename = f"{image_counter:03d}.{ext}"
                        local_file_path = os.path.join(local_chapter_folder, filename)
                        
                        if save_format in ['jpeg', 'webp']:
                            img_obj.save(local_file_path, save_format, quality=90)
                        elif save_format == 'png':
                            img_obj.save(local_file_path, 'png') 

                        images_downloaded += 1
                        image_counter += 1
                
                if images_downloaded > 0:
                    if merge_images:
                        merge_chapter_images(local_chapter_folder, image_format) 
                    chapters_processed += 1
                else:
                    print(f"[ERROR LOG] No images were successfully downloaded in chapter {current_chapter_num}.")
                    if os.path.exists(local_chapter_folder): shutil.rmtree(local_chapter_folder)
                
            except Exception as e:
                print(f"[ERROR LOG] Chapter {current_chapter_num} failed: {e}")
                if os.path.exists(local_chapter_folder): shutil.rmtree(local_chapter_folder)
                continue
        
        # 4. Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© (Ø§Ù„Ø¶ØºØ· ÙˆØ§Ù„Ø±ÙØ¹)
        if chapters_processed == 0:
            return {"success": False, "error": "**Ù„Ù… ÙŠØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ùˆ ØªÙ†Ø²ÙŠÙ„ Ø£ÙŠ ÙØµÙˆÙ„ Ø¨Ù†Ø¬Ø§Ø­.**"}

        unique_id = uuid.uuid4().hex[:8]
        zip_filename = f"manga_{unique_id}.zip"
        local_zip_path = os.path.join(os.getcwd(), zip_filename)

        # Ø§Ù„Ø¶ØºØ·
        with zipfile.ZipFile(local_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk(LOCAL_TEMP_DIR):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, LOCAL_TEMP_DIR)
                    zipf.write(file_path, arcname)
        
        # Ø§Ù„Ø±ÙØ¹ Ø¥Ù„Ù‰ Dropbox
        dropbox_path = f"/{zip_filename}"
        with open(local_zip_path, 'rb') as f:
            dbx.files_upload(f.read(), dropbox_path, mode=dropbox.files.WriteMode('overwrite'))

        # Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ©
        shared_link = ""
        try:
            shared_link_metadata = dbx.sharing_create_shared_link_with_settings(dropbox_path)
            shared_link = shared_link_metadata.url
        except dropbox.exceptions.ApiError as e:
            if e.error.is_shared_link_already_exists():
                shared_links = dbx.sharing_list_shared_links(path=dropbox_path, direct_only=True).links
                if shared_links:
                    shared_link = shared_links[0].url
            else:
                shared_link = "(ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· Ù…Ø´Ø§Ø±ÙƒØ©)"

        # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©
        return {
            "success": True, 
            "shared_link": shared_link, 
            "chapters_processed": chapters_processed,
            "zip_path": local_zip_path,
            "dropbox_path": dropbox_path,
            "url_was_fixed": not url_contains_chapter_num and chapters == 1
        }

    except Exception as e:
        print(f"[CRITICAL ERROR] Download task failed: {e}")
        return {"success": False, "error": f"ÙØ´Ù„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©: {e}"}
        
    finally:
        # Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        if driver: driver.quit()
        if os.path.exists(LOCAL_TEMP_DIR): shutil.rmtree(LOCAL_TEMP_DIR)


# --- Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø¨ÙˆØª ---

@bot.event
async def on_ready():
    # ... (ÙƒÙ…Ø§ Ù‡Ùˆ) ...
    print(f'Bot is ready. Logged in as {bot.user}')
    try:
        synced = await bot.tree.sync()
        print(f"Synced {len(synced)} slash commands.")
        dbx.users_get_current_account()
        print("Dropbox connection successful.")
    except Exception as e:
        print(f"Dropbox connection failed or slash commands sync failed: {e}")


# --- Ø£Ù…Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ (Slash Command) ---

@bot.tree.command(name="download", description="ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ± Ù…Ù† Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù…Ø§Ù†Ø¬Ø§ ÙˆØ¶ØºØ·Ù‡Ø§ ÙˆØ±ÙØ¹Ù‡Ø§.")
@discord.app_commands.describe(
    url="Ø±Ø§Ø¨Ø· ØµÙØ­Ø© Ø§Ù„Ù…Ø§Ù†Ø¬Ø§/Ø§Ù„ÙˆÙŠØ¨ØªÙˆÙ†",
    chapter_number="Ø±Ù‚Ù… Ø§Ù„ÙØµÙ„ Ø§Ù„Ø£ÙˆÙ„ Ø§Ù„Ø°ÙŠ Ø³ÙŠØ¨Ø¯Ø£ Ø¨Ù‡ Ø§Ù„ØªØ±Ù‚ÙŠÙ… (Ø§ÙØªØ±Ø§Ø¶ÙŠ 1)",
    chapters="Ø¹Ø¯Ø¯ Ø§Ù„ÙØµÙˆÙ„ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­Ù…ÙŠÙ„Ù‡Ø§ (Ø§ÙØªØ±Ø§Ø¶ÙŠ 1)",
    merge_images="Ø¯Ù…Ø¬ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬Ø© ÙÙŠ ÙƒÙ„ ÙØµÙ„ (JPG ÙÙ‚Ø· - Ø§ÙØªØ±Ø§Ø¶ÙŠ: False)", # ØªÙ… ØªØºÙŠÙŠØ± Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„ØºÙŠØ± Ù…Ø±ØºÙˆØ¨ ÙÙŠÙ‡
    image_format="ØµÙŠØºØ© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (Ù…Ø«Ù„: jpg, webp, png - Ø§ÙØªØ±Ø§Ø¶ÙŠ: jpg)"
)
async def download_command(
    interaction: discord.Interaction, 
    url: str,
    chapter_number: int = 1,
    chapters: int = 1,       
    merge_images: bool = False,
    image_format: str = "jpg"
):
    user_mention = interaction.user.mention
    
    # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø£ÙˆÙ„ÙŠ
    if image_format.lower() not in VALID_FORMATS:
        error_msg = f"âŒ **ØµÙŠØºØ© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©!** Ø§Ù„ØµÙŠØº Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø© Ù‡ÙŠ: {', '.join(VALID_FORMATS)}."
        await interaction.response.send_message(error_msg, ephemeral=True)
        return

    initial_embed = discord.Embed(
        title="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ ÙØµÙ„ Ø§Ù„Ù…Ø§Ù†Ù‡ÙˆØ§",
        description=f"{user_mention} **Ø¬Ø§Ø±Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©ØŒ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±...** âŒ›",
        color=discord.Color.dark_grey()
    )
    
    # ÙŠØ¬Ø¨ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø¯ Ø§Ù„Ù…Ø¨Ø¯Ø¦ÙŠ Ø¨Ø³Ø±Ø¹Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡ Ø¨Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
    await interaction.response.send_message(embed=initial_embed, ephemeral=False)
    original_response = await interaction.original_response()

    # 2. ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø© ÙÙŠ Ø®ÙŠØ· Ù…Ù†ÙØµÙ„ (ÙŠÙ…Ù†Ø¹ Ø­Ø¸Ø± Ø§Ù„Ù€ Heartbeat)
    try:
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… asyncio.to_thread Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø© ÙÙŠ Ø®ÙŠØ· Ø§Ù„Ø¹Ø§Ù…Ù„
        result = await asyncio.to_thread(
            _process_manga_download,
            url,
            chapter_number,
            chapters,
            merge_images,
            image_format.lower()
        )
    except Exception as e:
        print(f"[CRITICAL ERROR] asyncio.to_thread failed: {e}")
        result = {"success": False, "error": f"ÙØ´Ù„ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…: {e}"}

    # 3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    if result["success"]:
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¶ØºÙˆØ· Ù…Ø­Ù„ÙŠÙ‹Ø§ Ø¨Ø¹Ø¯ Ù†Ø¬Ø§Ø­ Ø§Ù„Ø±ÙØ¹
        if os.path.exists(result["zip_path"]): os.remove(result["zip_path"])
        
        # Ø¬Ø¯ÙˆÙ„Ø© Ù…Ù‡Ù…Ø© Ø­Ø°Ù Ù…Ù„Ù Dropbox
        bot.loop.create_task(cleanup_dropbox_file(result["dropbox_path"], CLEANUP_DELAY_SECONDS))
        
        final_embed = discord.Embed(
            title="âœ… ØªÙ… Ø§Ù„Ø±ÙØ¹ Ø¥Ù„Ù‰ Dropbox",
            description=f"{user_mention} **ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­!**\n\n**Ø±Ø§Ø¨Ø· Ø§Ù„ØªØ­Ù…ÙŠÙ„:**\n{result['shared_link']}\n\n"
                        f"**Ù…Ù„Ø§Ø­Ø¸Ø©:** Ø³ÙŠØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¨Ø¹Ø¯ **{CLEANUP_DELAY_SECONDS // 60} Ø¯Ù‚ÙŠÙ‚Ø©**.",
            color=discord.Color.green()
        )
        footer_text = f"ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© {result['chapters_processed']} ÙØµÙ„/ÙØµÙˆÙ„ Ø¨Ù†Ø¬Ø§Ø­. Ø§Ù„ØµÙŠØºØ©: {image_format.upper()}. Ø§Ù„Ø¯Ù…Ø¬: {'Ù…ÙØ¹Ù„' if merge_images else 'ØºÙŠØ± Ù…ÙØ¹Ù„'}."
        # Ø¥Ø¶Ø§ÙØ© ØªØ­Ø°ÙŠØ± Ø¥Ø°Ø§ ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø¹Ø¯Ø¯ Ø§Ù„ÙØµÙˆÙ„ Ø¥Ù„Ù‰ 1
        if result.get('url_was_fixed'):
            footer_text += " (ØªØ­Ø°ÙŠØ±: ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙØµÙ„ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· Ù„Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù†Ù…Ø· ØªØ±Ù‚ÙŠÙ… ÙˆØ§Ø¶Ø­)."
            
        final_embed.set_footer(text=footer_text)
        
        await original_response.edit(embed=final_embed)
    else:
        error_embed = discord.Embed(
            title="âŒ ÙØ´Ù„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©",
            description=f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:\n**{result.get('error', 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}**",
            color=discord.Color.red()
        )
        await original_response.edit(embed=error_embed)

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª
bot.run(DISCORD_BOT_TOKEN)
